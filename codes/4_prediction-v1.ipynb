{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://phdinds-aim.github.io/time_series_handbook/08_WinningestMethods/lightgbm_m5_forecasting.html\n",
    "\n",
    "https://www.kaggle.com/code/ratan123/m5-forecasting-lightgbm-with-timeseries-splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO in fine tuning\n",
    "params = {'num_leaves': 555,\n",
    "          'min_child_weight': 0.034,\n",
    "          'feature_fraction': 0.379,\n",
    "          'bagging_fraction': 0.418,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'objective': 'regression',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.005,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'rmse',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3899,\n",
    "          'reg_lambda': 0.648,\n",
    "          'random_state': 222,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read data\n",
    "train_df = pd.read_csv(\"../data/preprocessed_train_df.csv\")\n",
    "test_df = pd.read_csv(\"../data/preprocessed_test_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "id_cols = ['Client', 'Warehouse', 'Product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for forecast_horizon create separate dataframes for training and prediction\n",
    "columns = ['holiday_count', 'is_holiday', 'is_prev_1week_holidays', 'is_prev_2week_holidays',\n",
    "           'year', 'month', 'week', 'day', 'day_of_week', 'quarter']\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for horizon, date in enumerate(test_df['ds'].unique()):\n",
    "    horizon_specific_cols = ['sales_lag_ph_{i}' for i in range(horizon, 14+10)] +\\\n",
    "                            ['price_lag__ph_{i}' for i in range(horizon, 14+10)] +\\\n",
    "                            ['price_rolling_mean_ph_{i}' for i in range(horizon, 14+10)] +\\\n",
    "                            ['price_rolling_std_ph_{i}' for i in range(horizon, 14+10)] +\\\n",
    "                            ['sales_rolling_std_ph_{i}' for i in range(horizon, 14+10)] +\\\n",
    "                            ['sales_rolling_mean_ph_{i}' for i in range(horizon, 14+10)]\n",
    "    \n",
    "    x_train = train_df[columns+horizon_specific_cols].copy()\n",
    "    y_train = train_df['y'].copy()\n",
    "\n",
    "    x_pred = test_df[test_df['ds']==date][columns+horizon_specific_cols].copy()\n",
    "\n",
    "    pred_combo = test_df[id_cols+['ds']]\n",
    "\n",
    "    clf = lgb.train(params, [x_train, y_train], 2500)\n",
    "\n",
    "    joblib.dump(f\"../model/vn1_horizon_{horizon}\".pkl)\n",
    "\n",
    "    pred_combo['prediction'] = clf.predict(x_pred)\n",
    "    predictions.append(pred_combo)\n",
    "\n",
    "    del x_train, y_train, x_pred\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates = test_df['ds'].unique()\n",
    "# predictions_df = dict(zip(dates, predictions))\n",
    "\n",
    "# predictions_df = pd.DataFrame(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_sales = pd.read_csv(\"../data/actual_sales_p2.csv\")\n",
    "actual_sales['ds'] = pd.to_datetime(actual_sales['ds'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out =actual_sales.merge(predictions_df, on = [id_cols+['ds']], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import custom_error\n",
    "\n",
    "cerr_mod = custom_error(out['y'], out['prediction'])\n",
    "print('  LightGBM Error For all Horizons: %.4f' % cerr_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
